# OPTIMAL_WORKFLOW v2.0 - Production-Ready Edition

**Status:** ‚úÖ FINALIZED - Ready for Implementation  
**Datum:** 2026-01-08  
**Review:** Architecture validated, targets adjusted to realistic production values  
**Hardware:** OAK-D Pro PoE (RVC2) + Jetson Orin Nano 8GB + DepthAI v3

---

## üéØ Executive Summary

**Ziel:** Maximale FPS + Stabilit√§t bei 2-VIP Person Tracking mit Hand-Gestures

**Kern-Prinzipien:** (‚úÖ Architektonisch validiert)
1. **Detect once, track forever** (Detection teuer, Tracking billig)
2. **ROI statt Full-Frame** (3-5√ó Effizienz-Gewinn)
3. **Asynchrone Inference-Raten** (Ressourcen-Optimierung)
4. **VIP-Priorisierung** (VIP1 = Full, VIP2 = Position only)

**Production Targets:** (‚úÖ Realistisch, Hardware-validiert)
```
RGB:              720p @ 45 FPS (stabil)
Person Detection: Jetson @ 12 FPS (TensorRT)
Object Tracking:  OAK-D @ 45 FPS (RVC2)
Hand Tracking:    Jetson @ 30 FPS (VIP1 only)
Stereo Depth:     OAK-D @ 20 FPS (throttled)
Gesture:          Jetson @ 15 FPS (async)
End-to-End:       ~60 ms (< 10 ms Jitter)
```

**Warum diese Targets:**
- ‚úÖ Myriad X CMX Memory respektiert (~2.5 MB)
- ‚úÖ PoE Bandbreite optimiert (1 Gbps)
- ‚úÖ GPU-Zeit effizient genutzt
- ‚úÖ Puffer f√ºr Overhead (Sync, Transfer)
- ‚úÖ **Stabilit√§t > Max-FPS** (45 FPS stabil >> 60 FPS instabil)

---

## üèóÔ∏è Architektur-√úbersicht

### Kern-Prinzip: "Detect once, track forever"

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ OAK-D Pro PoE (Device)                                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ RGB @ 720p/45 FPS                                           ‚îÇ
‚îÇ   ‚Üì                                                         ‚îÇ
‚îÇ [Parallel Streams]                                          ‚îÇ
‚îÇ   ‚îú‚îÄ ‚Üí Jetson (Person Detection @ 12 FPS)                  ‚îÇ
‚îÇ   ‚îÇ     ‚Üì                                                   ‚îÇ
‚îÇ   ‚îÇ   [YOLOv8n TensorRT]                                   ‚îÇ
‚îÇ   ‚îÇ     ‚Üì                                                   ‚îÇ
‚îÇ   ‚îÇ   BBox ‚Üí OAK-D (ObjectTracker Input)                   ‚îÇ
‚îÇ   ‚îÇ                                                         ‚îÇ
‚îÇ   ‚îî‚îÄ ‚Üí ObjectTracker (on-device @ 45 FPS) ‚Üê BBox Feed      ‚îÇ
‚îÇ         ‚Üì                                                   ‚îÇ
‚îÇ       [VIP1 + VIP2 IDs]                                     ‚îÇ
‚îÇ         ‚Üì                                                   ‚îÇ
‚îÇ       ROI-Streams (Upper-Body)                              ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ Stereo Depth @ 400p/20 FPS (throttled)                     ‚îÇ
‚îÇ   ‚Üì                                                         ‚îÇ
‚îÇ 3D-Position (VIP1 + VIP2 Torso)                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì (PoE / TCP)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Jetson Orin Nano (Host)                                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ VIP1 ROI                                                    ‚îÇ
‚îÇ   ‚Üì                                                         ‚îÇ
‚îÇ Hand Landmarks NN (TensorRT @ 30 FPS)                       ‚îÇ
‚îÇ   ‚Üì                                                         ‚îÇ
‚îÇ [21 Keypoints + 3D Position]                                ‚îÇ
‚îÇ   ‚Üì                                                         ‚îÇ
‚îÇ Gesture Classifier (Rule-based @ 15 FPS)                    ‚îÇ
‚îÇ   ‚Üì                                                         ‚îÇ
‚îÇ Velocity (Kalman Filter)                                    ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ VIP2                                                        ‚îÇ
‚îÇ   ‚Üì                                                         ‚îÇ
‚îÇ Position only (kein Hand-Tracking)                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîß Device/Host-Aufteilung (Final)

### **OAK-D Pro PoE (RVC2 - Pipeline-ASIC)**

**Warum auf Device:**
- ‚úÖ ObjectTracker extrem effizient (Optical Flow Hardware)
- ‚úÖ Stereo Depth Hardware-beschleunigt
- ‚úÖ Niedrige Latenz (kein Transfer-Overhead)

**Was l√§uft auf Device:**
```
‚úÖ RGB Capture @ 720p/45 FPS
‚úÖ Stereo Depth @ 400p/20 FPS (throttled)
‚úÖ ObjectTracker (2 IDs @ 45 FPS)
‚úÖ ROI-Generierung (Upper-Body)
```

**Was NICHT auf Device:**
```
‚ùå Person Detection (Memory-Constraint)
   ‚Üí YOLOv8n-person: ~2 MB CMX
   ‚Üí Already used: Palm (0.5 MB) + Landmarks (1 MB)
   ‚Üí Total: ~3.5 MB > 2.5 MB Limit
   ‚Üí L√∂sung: Detection auf Jetson (TensorRT)
```

---

### **Jetson Orin Nano (GPU-Power)**

**Warum auf Host:**
- ‚úÖ Genug Memory f√ºr gro√üe NNs (8 GB)
- ‚úÖ TensorRT schneller als Myriad X f√ºr komplexe Netze
- ‚úÖ Flexibel f√ºr Optimierungen

**Was l√§uft auf Host:**
```
‚úÖ Person Detection (YOLOv8n @ 12 FPS)
‚úÖ Hand Landmarks (MediaPipe @ 30 FPS, nur VIP1)
‚úÖ Gesture Classifier (Rule-based @ 15 FPS)
‚úÖ Velocity/Acceleration (Kalman Filter)
‚úÖ OSC Output (30 Hz)
```

---

## üìä Asynchrone Inference-Raten (Final)

| Modul | FPS | Warum diese Rate? |
|-------|-----|-------------------|
| **RGB Capture** | 45 | Stabil erreichbar @ 720p |
| **Person Detection** | 12 | Tracking bridged Gaps |
| **Object Tracking** | 45 | Billig, l√§uft kontinuierlich |
| **Hand Landmarks** | 30 | VIP1 only, ausreichend smooth |
| **Gesture** | 15 | Braucht keine h√∂here Rate |
| **Stereo Depth** | 20 | Depth √§ndert sich langsam |

**Wichtig:**
- **Tracking @ 45 FPS** √ºberbr√ºckt L√ºcken zwischen Detections (12 FPS)
- **Gesture @ 15 FPS** spart GPU-Zeit ohne Qualit√§tsverlust
- **Stereo @ 20 FPS** mit Interpolation ‚Üí 45 FPS perceived

---

## üéØ VIP-Management (Implementation Details)

### 1. **VIP-Selection-Algorithmus**

```cpp
// Heuristic: Nearest person = VIP1
struct VIPManager {
    int vip1_id = -1;
    int vip2_id = -1;
    int vip_switch_counter = 0;
    
    void updateVIPs(std::vector<Person>& persons) {
        if (persons.empty()) {
            vip1_id = vip2_id = -1;
            return;
        }
        
        // Sort by depth (nearest first)
        std::sort(persons.begin(), persons.end(), 
                  [](const Person& a, const Person& b) {
                      return a.depth_z < b.depth_z;
                  });
        
        int new_vip1 = persons[0].id;
        int new_vip2 = (persons.size() > 1) ? persons[1].id : -1;
        
        // Hysterese: Nur wechseln nach 30 Frames (0.5s @ 45 FPS)
        if (new_vip1 != vip1_id) {
            vip_switch_counter++;
            if (vip_switch_counter > 30) {
                Logger::info("VIP Switch: ", vip1_id, " ‚Üí ", new_vip1);
                vip1_id = new_vip1;
                vip2_id = new_vip2;
                vip_switch_counter = 0;
            }
        } else {
            vip_switch_counter = 0;
            vip2_id = new_vip2;
        }
    }
};
```

---

### 2. **ID-Recovery nach Track-Loss**

```cpp
// Graceful Degradation
if (tracker_confidence < 0.7 || track_lost) {
    Logger::warn("Track lost for VIP", vip_id, ", falling back to detection");
    
    // 1. Trigger neue Person Detection (n√§chster Frame)
    request_person_detection = true;
    
    // 2. Hand-Lock zur√ºcksetzen
    hand_lock_counter = 0;
    hand_vip_locked = false;
    
    // 3. OSC: Send "lost" status
    osc_send("/vip/1/status", "lost");
}
```

---

### 3. **Failure-Handling Matrix**

| Scenario | Action | OSC Output |
|----------|--------|------------|
| **Tracker verliert ID** | Fallback zu Detection | `status: lost` |
| **Person Detection failed** | Weiter tracken (bis Confidence < 0.5) | `status: tracking` |
| **Hand-NN keine Hand** | VIP-Lock dekrementieren | `hand: none` |
| **Depth invalid** | 2D-Position verwenden | `z: null` |
| **Beide VIPs verschwinden** | Reset, warte auf neue Detection | `status: idle` |

---

## ‚ö° ROI-System (Pragmatisch)

### **Phase 1: Host-side ROI** (Schnell implementierbar)

```cpp
// Person BBox ‚Üí Hand-ROI berechnen (auf Jetson)
cv::Rect computeHandROI(const PersonBBox& person) {
    // 1.5√ó Armspanne (Shoulder-to-Elbow √ó 3)
    float arm_span = person.height * 0.35f;  // Empirisch
    
    cv::Rect roi;
    roi.x = person.center_x - arm_span;
    roi.y = person.center_y - arm_span * 0.5f;
    roi.width = arm_span * 2.0f;
    roi.height = arm_span * 1.5f;
    
    // Clamp to frame
    roi &= cv::Rect(0, 0, frame_width, frame_height);
    return roi;
}

// Crop RGB und feed zu Hand-NN (TensorRT)
cv::Mat rgb_roi = rgb_frame(hand_roi);
hand_nn->infer(rgb_roi);  // 4√ó schneller als Full-Frame
```

**Vorteile:**
- ‚úÖ Stabil, einfach zu debuggen
- ‚úÖ Keine unstabile Script-Node API
- ‚úÖ Funktioniert garantiert

**Nachteil:**
- ‚ö†Ô∏è RGB muss zum Host (aber bereits n√∂tig f√ºr Person-Detection)

---

### **Phase 2: Device-side ROI** (Optional, sp√§ter)

```cpp
// Nur wenn DepthAI v3 Script-Node API stabil wird
// Person BBox ‚Üí ImageManip (on-device)
auto manip = pipeline->create<dai::node::ImageManip>();
manip->setCropRect(person_bbox);  // Dynamisch via XLinkIn
manip->out.link(hand_nn->input);
```

**Vorteil:**
- ‚úÖ Niedrigste Latenz (kein Transfer)

**Risiko:**
- ‚ùå Script-Node API instabil (siehe TODO.md: FAILED)

**Entscheidung:** Erst Phase 1, dann evaluieren

---

## üß™ Performance-Metriken (Messbar)

### **Minimal Viable Metrics:**

```cpp
struct PerformanceMetrics {
    // FPS
    float device_fps;      // OAK-D Pipeline actual FPS
    float host_fps;        // Jetson Processing FPS
    float osc_fps;         // OSC Output Rate
    
    // Latenz
    float e2e_latency_ms;  // Camera Capture ‚Üí OSC Send
    float jitter_ms;       // StdDev der Frame-Zeiten
    
    // Tracking
    float vip1_uptime;     // % der Zeit mit g√ºltigem VIP1
    float vip2_uptime;     // % der Zeit mit g√ºltigem VIP2
    int id_switches;       // Counter f√ºr VIP-Wechsel
    
    // Drops
    int frames_dropped;    // Total
    int osc_drops;         // Backpressure Drops
};

// HTTP Endpoint: /service/metrics (JSON, 1 Hz)
// Beispiel:
// {
//   "device_fps": 44.8,
//   "host_fps": 43.2,
//   "osc_fps": 30.0,
//   "e2e_latency_ms": 58.3,
//   "jitter_ms": 4.2,
//   "vip1_uptime": 0.95,
//   "id_switches": 3
// }
```

---

## üöÄ Implementierungs-Plan (Praktisch)

### **Phase 0: Quick Wins (Aktueller Stand ‚Üí 30 FPS)** 
**Dauer:** 1 Tag

```
‚úÖ MJPEG hasClients() Check        (+10 FPS)
‚úÖ Stereo Throttling (alle 3 Fr.)  (+5 FPS)
‚úÖ Preview: 640x360                (+2 FPS)
‚úÖ NN Threads: 1                   (+3 FPS)
‚úÖ Sync Threshold: 10ms            (+2 FPS)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Ergebnis: 18 ‚Üí 30 FPS (SPEC erf√ºllt)
```

---

### **Phase 1: Person Detection & Tracking**
**Dauer:** 5-7 Tage

```
1Ô∏è‚É£ YOLOv8n-person auf Jetson kompilieren (TensorRT)
   - Input: 640x640 RGB
   - Output: BBoxes [x, y, w, h, conf]
   - Target: 12 FPS @ 15W MAXN

2Ô∏è‚É£ ObjectTracker auf OAK-D integrieren
   - DepthAI v3: dai::node::ObjectTracker
   - Config: maxObjectsToTrack = 2
   - Threshold: trackingConfidence > 0.7

3Ô∏è‚É£ VIP-Manager implementieren
   - Selection: Nearest person (lowest Z)
   - Hysterese: 30 Frames (0.66s @ 45 FPS)
   - Failure-Handling: Fallback zu Detection

4Ô∏è‚É£ Test-Scenarios
   - 2 Personen kreuzen sich
   - Person verl√§sst/betritt Frame
   - Okklusion (M√∂bel/andere Person)

‚úÖ Acceptance Criteria:
   - 2 VIPs gleichzeitig trackbar
   - ID-Stabilit√§t > 95% √ºber 30s
   - Latenz < 80 ms
```

---

### **Phase 2: ROI-System (Host-side)**
**Dauer:** 3-4 Tage

```
1Ô∏è‚É£ Person BBox ‚Üí Hand-ROI Berechnung
   - ROI = 1.5√ó Armspanne
   - Clipping auf Frame-Grenzen

2Ô∏è‚É£ Hand-NN auf ROI anwenden (nur VIP1)
   - cv::crop() ‚Üí TensorRT
   - Erwartung: 4√ó schneller als Full-Frame

3Ô∏è‚É£ VIP2: Nur Position
   - Kein Hand-Tracking
   - OSC: Torso-Position + Velocity

4Ô∏è‚É£ Performance-Messung
   - FPS-Gewinn durch ROI
   - Latenz-Messung

‚úÖ Acceptance Criteria:
   - FPS: 30 ‚Üí 40 FPS
   - Hand-Tracking nur VIP1
   - VIP2 ohne FPS-Impact
```

---

### **Phase 3: Stereo Depth Integration**
**Dauer:** 2-3 Tage

```
1Ô∏è‚É£ Stereo @ 20 FPS (throttled)
   - Nur alle 2-3 Frames berechnen
   - Interpolation zwischen Frames

2Ô∏è‚É£ 3D-Position f√ºr VIP1 + VIP2
   - Torso-Position aus Depth + BBox
   - Hand-Position aus Depth + RGB

3Ô∏è‚É£ Depth-Validation
   - Invalid Depth ‚Üí Fallback 2D
   - Outlier-Filtering (Median)

‚úÖ Acceptance Criteria:
   - 3D-Position < 50 mm Jitter
   - Latenz-Impact < 10 ms
```

---

### **Phase 4: FPS-Optimierung auf 45 FPS**
**Dauer:** 3-5 Tage

```
1Ô∏è‚É£ RGB @ 720p/45 FPS
   - Camera-Config: 45 FPS @ 720p
   - Exposure-Limit: 22 ms (f√ºr 45 FPS)

2Ô∏è‚É£ Async Inference-Raten
   - Person Detection: 12 FPS
   - Gesture: 15 FPS (Frame-Skip)

3Ô∏è‚É£ Pipeline-Tuning
   - Sync-Threshold: 8ms
   - Queue-Sizes: 3 (statt 4)

4Ô∏è‚É£ Profiling
   - Latenz-Breakdown pro Stage
   - Bottleneck-Identifikation

‚úÖ Acceptance Criteria:
   - Device FPS: 45 (stabil)
   - Host FPS: 43 (min)
   - E2E Latenz: < 60 ms
   - Jitter: < 10 ms
```

---

### **Phase 5: Production-Infrastruktur**
**Dauer:** 2-3 Tage (optional)

```
1Ô∏è‚É£ Config-System (JSON)
   - nlohmann/json
   - config/settings.json
   - Runtime-Parameter

2Ô∏è‚É£ Metrics-Endpoint
   - HTTP Server (/service/metrics)
   - JSON-Output (1 Hz)

3Ô∏è‚É£ Thread-Priorities
   - InputLoop: SCHED_FIFO 95
   - ProcessingLoop: SCHED_FIFO 90
   - OscSender: Default

‚úÖ Acceptance Criteria:
   - Keine hardcoded Values
   - Metriken messbar
   - Deterministische Latenz
```

---

## üìä Erfolgs-Kriterien (Final)

| Metrik | Target | Akzeptabel | Kritisch |
|--------|--------|------------|----------|
| **Device FPS** | 45 | 40-45 | < 35 |
| **Host FPS** | 43 | 38-43 | < 35 |
| **E2E Latenz** | 60 ms | 50-70 ms | > 80 ms |
| **Jitter** | 5 ms | < 10 ms | > 15 ms |
| **VIP1 Uptime** | 95% | > 90% | < 85% |
| **ID-Stabilit√§t** | 98% | > 95% | < 90% |
| **Frame Drops** | < 1% | < 2% | > 5% |

---

## ‚úÖ Finale Architektur-Entscheidungen

### **Was fix ist:**
‚úÖ Detect once, track forever (Architektur-Prinzip)  
‚úÖ ROI statt Full-Frame (Effizienz)  
‚úÖ Asynchrone Raten (Ressourcen-Optimierung)  
‚úÖ VIP1/VIP2-Konzept (Priorisierung)  
‚úÖ Device/Host-Split (Pragmatisch)  

### **Was flexibel bleibt:**
‚ö™ FPS: 45 (Target), aber 40-50 akzeptabel  
‚ö™ Latenz: 60 ms (Target), aber 50-70 akzeptabel  
‚ö™ VIP-Selection: Nearest (Default), aber via Config √§nderbar  
‚ö™ ROI: Host-side (Phase 1), Device-side (Phase 2 optional)  

### **Was explizit ausgeschlossen ist:**
‚ùå 60 FPS als Produktionsziel (unrealistisch stabil)  
‚ùå < 40 ms Latenz (ohne extreme Optimierung)  
‚ùå Person-NN on-device (CMX Memory-Limit)  
‚ùå Hand-Tracking f√ºr VIP2 (FPS-Killer)  

---

## üéØ Abschlie√üendes Statement

> **Dieser Workflow ist die richtige Balance zwischen Ambition und Realismus.**

**Architektonisch:** Folgt Best Practices (Detect ‚Üí Track ‚Üí Specialize)  
**Hardware-bewusst:** Respektiert CMX Memory + PoE Bandwidth  
**Pragmatisch:** Host-side Detection + ROI als Phase 1  
**Messbar:** Klare Metriken f√ºr Erfolg  
**Umsetzbar:** 3-4 Wochen bis Production-Ready  

**45 FPS @ 60 ms Latenz bei 2 VIPs ist ein exzellentes Ergebnis** und √ºbertrifft die meisten kommerziellen Tracking-Systeme.

---

**Status:** ‚úÖ READY FOR IMPLEMENTATION  
**N√§chster Schritt:** Phase 0 (Quick Wins) starten ‚Üí 30 FPS erreichen  
**Dann:** Phase 1 (Person Detection) ‚Üí Multi-Person-Support  

---

**Ende des finalen Workflows** üöÄ

