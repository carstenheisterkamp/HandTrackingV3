# Model Testing Guide: Lite vs Full

**Datum:** 2026-01-10  
**Ziel:** Vergleiche `lite` vs `full` Modelle fÃ¼r bessere Gestenerkennung

---

## ğŸ¯ Schnellstart

### Schritt 0: Status prÃ¼fen (auf Jetson)

```bash
cd ~/dev/HandTrackingV3
./scripts/check_models.sh
```

**Zeigt:**
- Welche TFLite Models vorhanden sind
- Welche ONNX Models konvertiert sind
- Welche TensorRT Engines gecached sind
- Was noch zu tun ist

### Schritt 1: PrÃ¼fe vorhandene Models (auf Jetson)

```bash
cd ~/dev/HandTrackingV3
ls -lh models/*.tflite
```

**Erwartete Modelle (sollten bereits vorhanden sein):**
- `palm_detection_lite.tflite` âœ…
- `hand_landmark_lite.tflite` âœ…
- `palm_detection_full.tflite` âœ… (oder via sh4/sh6 blob)
- `hand_landmark_full.tflite` âœ… (oder via sh4/sh6 blob)

**Falls Full Models fehlen:**
```bash
# Option 1: Von MediaPipe herunterladen
wget -P models/ https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/latest/hand_landmarker.task

# Option 2: Download-Script ausfÃ¼hren
python3 scripts/download_tflite_models.py
```


### Schritt 2: Zu ONNX konvertieren (auf Jetson)

```bash
cd ~/dev/HandTrackingV3
python3 scripts/convert_to_onnx.py
```

**Dies konvertiert (wenn noch nicht vorhanden):**
- `palm_detection_lite.tflite` â†’ `palm_detection.onnx` âœ…
- `hand_landmark_lite.tflite` â†’ `hand_landmark.onnx` âœ…
- `palm_detection_full.tflite` â†’ `palm_detection_full.onnx` â† NEU
- `hand_landmark_full.tflite` â†’ `hand_landmark_full.onnx` â† NEU

**Hinweis:** Script Ã¼berspringt bereits vorhandene ONNX-Dateien automatisch.

**Wichtig:** TensorRT baut beim ersten Start `.engine` Dateien (dauert ~2-3 Minuten).

### Schritt 3: Full Models aktivieren

**In `src/main.cpp` Zeile 38:**
```cpp
const bool USE_FULL_MODELS = true;  // â† Auf true setzen
```

### Schritt 4: Neu kompilieren und testen

```bash
# Auf Jetson
cd ~/dev/HandTrackingV3/cmake-build-debug-remote-host
ninja
sudo systemctl restart hand-tracking
```

### Schritt 5: ZurÃ¼ck zu Lite Models

**In `src/main.cpp` Zeile 38:**
```cpp
const bool USE_FULL_MODELS = false;  // â† Auf false setzen
```

Neu kompilieren: `ninja`

---

## ğŸ“Š Was zu testen

### Performance Metrics

**Ãœberwache im Log:**
```
FPS: XX.X                    â† Sollte bei 25-30 bleiben
TensorRT: Ready              â† Initalisierung erfolgreich
Hands Detected: X            â† Erkennungsrate
```

**Bei viel langsamerer FPS (<20):** ZurÃ¼ck zu Lite Models

### Gestenerkennung

Teste die problematischen Gesten:

| Geste | Problem (Lite) | Erwartung (Full) |
|-------|----------------|------------------|
| FIVE | Wird als FOUR erkannt | Besser? |
| FIST (2 HÃ¤nde) | Inkonsistent | Stabiler? |
| THUMBS_UP | Verwechslung mit FIST | ZuverlÃ¤ssiger? |
| POINTING | Verwechslung mit TWO | PrÃ¤ziser? |

**Test bei:**
- 40cm Abstand
- 80cm Abstand
- 120cm Abstand
- Verschiedene Winkel

### False Positives

- Gesicht noch erkannt? (sollte 0 sein mit Haar Cascade)
- Andere Objekte als Hand erkannt?

---

## ğŸ” Model Unterschiede

### Lite Models (Default)

**Palm Detection Lite:**
- Input: 192Ã—192
- Params: ~100K
- Inference: ~5-8ms auf Jetson

**Hand Landmark Lite:**
- Input: 224Ã—224
- Params: ~200K
- Keypoints: 21
- Inference: ~5-7ms auf Jetson

**Total:** ~12-15ms â†’ 60-80 FPS mÃ¶glich

### Full Models

**Palm Detection Full:**
- Input: 256Ã—256 (grÃ¶ÃŸer)
- Params: ~500K (5x mehr)
- Inference: ~10-15ms (langsamer)

**Hand Landmark Full:**
- Input: 256Ã—256 (grÃ¶ÃŸer)
- Params: ~1M (5x mehr)
- Keypoints: 21 (gleich)
- Inference: ~15-20ms (langsamer)

**Total:** ~25-35ms â†’ 28-40 FPS mÃ¶glich

**Vorteil Full:**
- Bessere Erkennung bei weiter Entfernung
- Robuster bei schwierigen Winkeln
- PrÃ¤zisere Landmark-Positionen

**Nachteil Full:**
- 2-3x langsamer
- GrÃ¶ÃŸere TensorRT Engines (mehr VRAM)
- LÃ¤ngere Init-Zeit

---

## ğŸ“ˆ Benchmark Template

### Test 1: FPS Impact

| Modell | FPS Avg | FPS Min | FPS Max | Inference Time |
|--------|---------|---------|---------|----------------|
| Lite   | 28.5    | 25.1    | 30.2    | ~15ms          |
| Full   | ?       | ?       | ?       | ?              |

### Test 2: Gestenerkennung Accuracy

| Geste | Lite Accuracy | Full Accuracy | Improvement |
|-------|---------------|---------------|-------------|
| FIVE  | 70%           | ?             | ?           |
| FIST  | 80%           | ?             | ?           |
| THUMBS_UP | 75%       | ?             | ?           |
| POINTING | 85%        | ?             | ?           |

*(Accuracy = richtig erkannt / 20 Versuche)*

### Test 3: False Positives

| Szenario | Lite | Full |
|----------|------|------|
| Gesicht im Bild | 0 | ? |
| Kein Hand im Bild | 0 | ? |
| Objekt (Tasse) | 0 | ? |

---

## ğŸ¯ Entscheidungskriterien

### Bleibe bei Lite wenn:
- âœ… FPS bleibt bei 25-30
- âœ… Gesten-Accuracy >85%
- âœ… Keine hÃ¤ufigen False Positives

### Wechsel zu Full wenn:
- âœ… FPS bleibt >20 FPS
- âœ… Gesten-Accuracy signifikant besser (>10% Verbesserung)
- âœ… Keine neuen False Positives

### Verwerfe Full wenn:
- âŒ FPS fÃ¤llt unter 20
- âŒ Keine signifikante Verbesserung (<5%)
- âŒ Mehr False Positives

---

## ğŸ”§ Troubleshooting

### Engine Build dauert ewig (>5 Minuten)
- Normal beim ersten Start mit Full Models
- TensorRT optimiert fÃ¼r Jetson Hardware
- Nur einmal nÃ¶tig, danach cached

### Out of Memory Error
- Full Models benÃ¶tigen mehr VRAM
- Jetson Orin Nano hat 8GB shared RAM/VRAM
- LÃ¶sung: ZurÃ¼ck zu Lite oder MAXN Mode aktivieren

### Keine FPS Verbesserung erkennbar
- Log zeigt "TensorRT: Building..." â†’ warte bis fertig
- Check `tegrastats` fÃ¼r GPU Utilization
- Stelle sicher, dass MAXN Mode aktiv ist

### Service startet nicht mehr
- Check Log: `journalctl -u hand-tracking -n 50`
- PrÃ¼fe ob ONNX Dateien existieren: `ls -lh models/*.onnx`
- Fallback: Setze `USE_FULL_MODELS = false` und rebuild

---

## ğŸ“ Notizen

**Wichtig:**
- Engine Dateien (`*.engine`) werden automatisch erstellt
- Sind Hardware-spezifisch (Jetson Orin Nano)
- MÃ¼ssen neu gebaut werden bei Model-Wechsel
- Liegen in `models/` neben `.onnx` Dateien

**Tipp:**
- Teste Full Models nur bei konkreten Erkennungsproblemen
- Lite Models sind fÃ¼r die meisten Anwendungen ausreichend
- Full Models kÃ¶nnten bei schlechten LichtverhÃ¤ltnissen helfen


