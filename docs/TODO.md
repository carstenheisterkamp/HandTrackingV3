# Development Plan & Status

## Phase 1: Foundation & Infrastructure
- [x] **Project Structure Setup**
    - *Why:* Establish standard C++ layout (include/src) and CMake configuration.
    - *Status:* Created basic folder structure (`include/core`, `src/core`, etc.).
- [x] **Core Utilities**
    - *Why:* Need lock-free communication before implementing threads.
    - *Status:* Implemented `SpscQueue.hpp` (Lock-free Ringbuffer) and `Logger.hpp`.
- [x] **Pipeline Manager Skeleton**
    - *Why:* Abstraction for DepthAI v3 device management.
    - *Status:* Implemented `PipelineManager` class. Migrated to correct v3 API pattern (build() and requestOutput()) to fix compilation errors.
- [x] **Logging & Error Handling**
    - *Why:* Essential for debugging on headless Jetson.
    - *Status:* Implemented `Logger` class.
- [ ] **Configuration System**
    - *Task:* Implement JSON config loader (e.g., using `nlohmann/json`).
    - *Goal:* Eliminate magic numbers. Allow runtime tuning of Filter/OSC parameters.
- [ ] **Runtime Camera Control (v3 CameraControl Messages)**
    - *Task:* Implement XLinkIn control queue for runtime parameter changes without service restart.
    - *Parameters to control:*
      - Manual Focus (0-255, for poor lighting conditions) **[BLOCKED: Requires XLinkIn queue implementation]**
      - Autofocus Mode (CONTINUOUS_VIDEO, AUTO, EDOF)
      - Autofocus Region (ROI for hand tracking area)
      - Manual Exposure (Âµs + ISO)
      - White Balance (color temperature K)
      - IR Laser/Flood Intensity (0.0-1.0) **[âœ… IMPLEMENTED: Set to 1.0 (100%) by default]**
    - *Interface Options:* OSC input (`/camera/focus/manual <value>`), Keyboard shortcuts, or STDIN commands
    - *Priority:* **HIGH** (Autofocus currently struggles in poor lighting, manual focus is critical)
    - *Current Status:* 
      - âœ… IR intensity at 100% (was 80%)
      - âŒ Manual focus NOT working (v3 API requires CameraControl Messages via XLinkIn queue)
      - ðŸ”´ **BLOCKER:** Must implement XLinkIn â†’ Camera Control pipeline connection first
      - Then send `CameraControl().setManualFocus(170)` messages at runtime
- [ ] **Device Reset Strategy for PoE Reconnect**
    - *Task:* If device reconnect issues persist, implement hardware reset option
    - *Options:*
      - Add `device->flashBootloader()` call for full firmware reset (aggressive)
      - Implement network-level reset for PoE (if available via API)
      - Add retry logic with exponential backoff (3s, 6s, 12s)
    - *Current Status:* Using `device->close()` + 2s wait (soft reset)
    - *Priority:* **Low** (only if current approach fails in production)

## Phase 2: Data Pipeline (Zero-Copy Focus)
- [x] **OAK-D Pipeline Configuration**
    - *Task:* Configure ColorCamera, ISP Scaling, and NeuralNetwork nodes.
    - *Goal:* Ensure 0% CPU load on Jetson for resizing.
    - *Status:* Implemented `PipelineManager` with `NeuralNetwork` and `Sync` nodes.
    - *Note (2026-01-06):* **StereoDepth removed from OAK-D** due to CMX memory constraints (~2.5MB limit). Running Palm Detection + Hand Landmarks NNs leaves no room for StereoDepth on the Myriad X chip.
- [x] **Memory Management Strategy**
    - *Task:* Implement `AlignedAllocator` and buffer pool.
    - *Goal:* 256-byte alignment for DMA compatibility.
    - *Status:* Implemented `MemoryUtils.hpp`, `Frame.hpp`, and `FramePool.hpp`. Added Mono L/R buffer support for future GPU stereo.
- [x] **Zero-Copy Implementation**
    - *Status:* Implemented GPU-accelerated Color Conversion (NPP) to reduce CPU load. Host->GPU is Zero-Copy via Pinned Memory.
    - *Note:* True Zero-Copy from OAK-D not possible (PoE data arrives in non-pinned memory). Single memcpy to pinned buffer is unavoidable.

## Phase 3: Tracking Engine
- [x] **Hand Landmark Decoding**
    - *Task:* Parse NN output tensors into C++ structures.
    - *Status:* Implemented in `ProcessingLoop`. Fixed FP16/FP32 mismatch using OpenCV.
- [x] **Palm Detection**
    - *Task:* Run Palm Detection NN to filter false positives.
    - *Status:* Implemented (2026-01-06). Runs on OAK-D alongside Landmarks NN.
- [ ] **Dynamic ROI Cropping (On-Device)** 
    - *Task:* Parse Palm Detection outputs (896 SSD anchors) and dynamically crop Hand Landmark input.
    - *Status:* **FAILED (2026-01-08)** - DepthAI Script-Node Python API is undocumented/broken.
        - Attempted APIs: `setCropRect()`, `setCenterCrop()`, `setResize()` - ALL throw AttributeError
        - Script-Node crashes device connection with X_LINK_ERROR
        - **Decision:** Rolled back to stable direct pipeline (full-frame 224x224 resize)
    - *Alternative:* Could implement ROI cropping on Jetson (host-side) but defeats Zero-Copy goal
    - *Priority:* **LOW** - Tracking works without it, just less efficient
- [x] **VIP Logic**
    - *Task:* Implement "Locking" mechanism (15 frames consistency check).
    - *Status:* Implemented in `ProcessingLoop`.
- [x] **Gesture Recognition**
    - *Task:* Implement heuristics for FIST, PINCH, FIVE, etc.
    - *Status:* Implemented in `ProcessingLoop` based on finger joint angles/distances.
- [x] **Filtering System**
    - [x] Kalman Filter (Position).
    - [x] One-Euro Filter (Jitter reduction). *Verified: Implemented in core/ProcessingLoop.*

## Phase 4: Networking & OSC
- [x] **Liblo Integration**
    - *Task:* Wrap `liblo` in a C++ class (`OscSender`).
    - *Status:* Implemented `OscSender` class.
- [x] **OSC Message Builder**
    - *Task:* Serialize tracking data to OSC blobs.
    - *Status:* Implemented in `OscSender::send`. Includes Gesture ID/Name.
- [x] **Backpressure Handling**
    - *Task:* Implement "Drop-Oldest" logic in the network thread.
    - *Status:* Implemented latency check in `OscSender` and non-blocking push in `ProcessingLoop`.

## Phase 6: Immediate Verification & Fixes (Current Focus)
- [ ] **Hand Tracking & Preview Fixes** (Implemented, awaiting verification)
    - *Issues:* Semi-transparent overlay, correct unit display (mm), robust gesture recognition, GPU performance.
    - *Fixes:* Rewrote `drawDebugOverlay`, implemented `unletterbox` for bounding boxes, rewrote gesture logic, moved Stereo call to 1x/frame.
- [ ] **Performance Optimization** (After Verification)
    - *Goal:* Reach reliable >30 FPS (currently ~22 FPS due to overhead).

## Phase 5: Optimization & Metrics
- [x] **Debug Preview (MJPEG)**
    - *Task:* HTTP Stream with visual overlay (Skeleton, BBox, Gestures).
    - *Priority:* **High** (Essential for tuning).
    - *Status:* Implemented MjpegServer with smart encoding (only when clients connected).
    - *Optimization (2026-01-08):* Skip JPEG encoding when no clients â†’ 18 FPS â†’ 30 FPS boost.
- [x] **Correction of Alignment/Aspect Ratio**
    - *Task:* Fix "Total Off" skeleton alignment due to STRETCH resizing.
    - *Status (2026-01-07):* Switched pipeline to `LETTERBOX` resize mode. Implemented `unletterbox()` helper to map padded coordinates back to original frame logic.
    - *Status (2026-01-08):* Verified with Pixel-Koordinaten-Normalisierung (0-224 â†’ 0-1) + Unletterbox.
- [x] **Stereo Depth Integration (Jetson GPU) - Infrastructure**
    - *Task:* Stream Mono L/R from OAK-D to Jetson.
    - *Status (2026-01-07):* Mono L/R cameras added to pipeline, synced with RGB/NN outputs. Frame structure extended with hasStereoData flag. Data copied to pinned memory in InputLoop.
    - *Status (2026-01-08):* **DISABLED** - Mono cameras removed from pipeline, GPU Stereo deaktiviert fÃ¼r Performance.
- [x] **Stereo Depth Computation (CUDA Kernel)**
    - *Task:* Implement GPU-based stereo matching (e.g., Block Matching or SGM) on Jetson.
    - *Status:* Implemented custom CUDA Kernel (`StereoKernel.cu`) for high-performance Block Matching on Orin Nano (replacing missing OpenCV CUDA module).
    - *Status (2026-01-08):* **DISABLED** in ProcessingLoop - nicht benÃ¶tigt ohne Mono-Kameras.
    - *Priority:* **Low** (Can re-enable when needed).
- [x] **Performance Optimization**
    - *Task:* Achieve 25-30 FPS @ 15W MAXN Mode.
    - *Status (2026-01-08):* **âœ… ACHIEVED**
      - MJPEG encoding nur bei Clients: 18 FPS â†’ 30 FPS
      - NN Threads reduziert: 2 â†’ 1 pro NN
      - Preview Size reduziert: 960x540 â†’ 640x360
      - Sync Threshold reduziert: 20ms â†’ 10ms
      - CPU Fallback deaktiviert: Nur GPU NPP
      - Stereo Depth deaktiviert: Keine unnÃ¶tige GPU-Last
- [ ] **Performance Monitor**
    - *Task:* Measure Glass-to-OSC latency (Latency from photon capture to network packet output).
    - *Todo:* Convert `imgFrame->getTimestamp()` correctly in InputLoop (currently using host arrival time) for precise measurement.
- [x] **Systemd Integration**
    - *Task:* Create service file with Realtime priorities.
    - *Status:* Implemented in `scripts/hand-tracking.service`.
    - *Todo:* Implement `pthread_setschedparam` (SCHED_FIFO) directly in C++ `InputLoop` for finer thread control.
- [ ] **Final Profiling**
    - *Task:* Verify CPU < 20% and Latency < 50ms.
    - *Current:* ~25-30 FPS achieved, CPU load TBD.
- [ ] **Configuration System**
    - *Task:* Implement JSON config loader.

---

## Change Log / Decisions
- **2026-01-08 (PM v4 - STEREO DEPTH RE-ENABLED)**:
  - **ðŸŽ¯ CRITICAL FIX: Stereo Depth vollstÃ¤ndig reaktiviert**
    - **Problem:** War voreilig deaktiviert wegen Performance-Bedenken
    - **Fix:** 
      - Mono Left/Right Kameras zurÃ¼ck in Pipeline (640x400 @ 30 FPS)
      - Stereo Frame Copying in InputLoop reaktiviert
      - GPU Stereo Computation in ProcessingLoop reaktiviert
    - **Impact:** Accurate Z-Koordinaten fÃ¼r alle Landmarks, essentiell fÃ¼r 3D Hand Tracking
    - **Performance:** GPU Stereo < 5ms pro Frame, keine signifikante FPS-Reduktion
- **2026-01-08 (PM v3 - Final Performance Fixes)**:
  - **âŒ ROLLBACK: Dynamic ROI Script-Node** - Nach mehreren Stunden Debugging: DepthAI Script-Node Python API ist nicht funktionsfÃ¤hig
    - **Problem:** ImageManipConfig in Script-Node hat KEINE der dokumentierten Methoden
      - `setCropRect()` â†’ AttributeError
      - `setCenterCrop()` â†’ AttributeError  
      - `setResize()` â†’ AttributeError
      - Jeder Versuch fÃ¼hrt zu Device-Crash mit X_LINK_ERROR
    - **Entscheidung:** ZurÃ¼ck zu stabiler direkter Pipeline (RGB â†’ ImageManip â†’ Landmark NN)
    - **Performance-Impact:** Landmark NN verarbeitet Full-Frame statt ROI (weniger effizient, aber funktional)
    - **Lessons Learned:** 
      - DepthAI Script-Node API ist undokumentiert und instabil
      - Nicht fÃ¼r Production verwenden ohne offizielle Beispiele
      - Host-side Processing ist verlÃ¤sslicher als On-Device-Scripts
  - **âœ… FIXED: Queue Creation** - Queues werden jetzt direkt nach Node-Erstellung erstellt (nicht lazy)
  - **âœ… FIXED: Stereo Kernel Bounds Check** - Kritischer Bug im CUDA Stereo-Kernel behoben (rx < 0 Check)
- **2026-01-08 (AM)**:
  - **Manual Focus Attempt (NOT WORKING):** Attempted to implement static manual focus but discovered DepthAI v3 API requires CameraControl Messages via XLinkIn queue AFTER pipeline start. Cannot set focus during pipeline construction.
    - **What DOES work:**
      - âœ… IR Dot Projector + Flood Light intensity increased to 100% (was 80%)
      - âœ… Helps autofocus in low-light but not a complete solution
    - **What DOESN'T work:**
      - âŒ `camera->setManualFocus()` doesn't exist in v3 during pipeline build
      - âŒ `config.manualFocus` parameter created but cannot be applied yet
    - **Next Steps:**
      - Must implement XLinkIn node for CameraControl input queue
      - Send runtime CameraControl messages: `ctrl.setManualFocus(170)`
      - See TODO â†’ "Runtime Camera Control" (now HIGH priority)
  - **NN Input Format Fixed:** Changed from `RGB888p` to `NV12` to let Neural Network handle internal format conversion. Should eliminate "Input image does not match NN" warnings.
  - **Stereo Depth (Custom CUDA):** Implemented `src/core/StereoKernel.cu` - a raw CUDA implementation of Block Matching (SAD). This bypasses the need for `opencv_cuda` (which is missing on standard Jetpack) and provides high-performance depth averaging on the Orin GPU.
  - **Gesture Recognition V2:** Completely rewrote gesture logic to use robust 2D-distance heuristics (Tip-to-Wrist vs. MCP-to-Wrist) instead of flawed 3D distance checks.
- **2026-01-07 (PM)**:
  - **CRITICAL FIX**: Fixed "Total Off" tracking alignment. Switched OAK Pipeline resize mode from `STRETCH` (distorted 16:9->1:1) to `LETTERBOX` (pads with black bars). Added `unletterbox` logic in host C++ to map coordinates back correctly.
  - **Performance Verification**: Confirmed Jetson Orin Nano is in 15W Mode (MAXN for this device). GPU clocks locked at 624MHz.
  - **Diagnostics**: `diagnose_jetson.sh` rewritten to correctly identify Orin Nano's "15W" mode as Maximum Performance.
- **2026-01-07 (AM)**:
  - **Mono L/R Cameras** added to pipeline for GPU-based stereo depth (streaming infrastructure complete).
  - **GPU Frequency Detection** improved with multiple fallback paths including tegrastats parsing.
  - **Performance Scripts** updated: jetson_max_performance.sh and setup_sudoers.sh rewritten for Orin Nano.
  - **Systemd Service** fixed for proper boot-time performance optimization.
  - **Landmark/Palm normalization** added: auto-detects pixel coordinates (>1.0) and normalizes.
  - **Debug logging** for NN outputs removed (confirmed layer structure).
- **2026-01-06**: 
  - **Major Architecture Change:** StereoDepth removed from OAK-D pipeline due to E_OUT_OF_MEM errors. The Myriad X chip (~2.5MB CMX) cannot fit StereoDepth + Palm Detection + Hand Landmarks simultaneously.
  - **New Architecture:** 
    - OAK-D: RGB Camera + Palm Detection NN + Hand Landmarks NN (stable)
    - Jetson: GPU-based Stereo Matching (TODO) + Processing + OSC Output
  - Palm Detection re-enabled after testing minimal pipeline stability.
  - Fixed CUDA buffer registration to handle already-registered buffers gracefully.
  - Reduced NN threads to 1 each to maximize stability.
- **2026-01-05**: Initialized project structure. Created `SpscQueue` to ensure thread safety from the start. Defined `PipelineManager` interface to encapsulate DepthAI v3 logic.
