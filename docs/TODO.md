# TODO: V3 3D Hand Controller Implementation

> **Aktuelle Phase:** Phase 2 - 2D Hand Tracking ABGESCHLOSSEN âœ…
> **Letztes Update:** 2026-01-09
> **Status:** âœ… Stabil @ 25-30 FPS mit 2 HÃ¤nden und Gesten

---

## ğŸ‰ MEILENSTEIN: Phase 2 Abgeschlossen!

**Datum:** 2026-01-09

**Was funktioniert:**
- âœ… **2-Hand Tracking** - Beide HÃ¤nde parallel erkannt und getrackt
- âœ… **Y-basierte Gesten** - Robust gegen Betrachtungswinkel
  - FIST âœŠ, THUMBS_UP ğŸ‘, POINTING â˜ï¸, PEACE âœŒï¸, FIVE ğŸ–ï¸, METAL ğŸ¤˜, etc.
- âœ… **Haar Cascade Face Filter** - Null False Positives im Gesicht
- âœ… **Kalman Tracking** - Smooth 6-State Filter
- âœ… **OSC Output** - Hand-IDs, Position, Velocity, Gesten
- âœ… **25-30 FPS** stabil mit voller Pipeline

---

## ğŸ¯ Aktuelle Aufgabe: Phase 2 Polish - ABGESCHLOSSEN

### Priorisierte Reihenfolge:
1. âœ… **Zwei HÃ¤nde erkennen** - FUNKTIONIERT
2. âœ… **Gesten-Erkennung** - Y-basierte Logik lÃ¤uft robust
3. âœ… **False Positive Filter** - Haar Cascade eliminiert Gesichter
4. â¬œ **Erweiterung auf 3D** (Stereo Depth) â†’ Phase 3

### Phase 2.6: Multi-Hand Support - âœ… FUNKTIONIERT
**Was wurde hinzugefÃ¼gt:**
- âœ… `PalmDetector::detectAll()` - Erkennt bis zu 2 HÃ¤nde
- âœ… `nmsMulti()` mit echtem IoU-basiertem NMS
- âœ… ProcessingLoop verarbeitet beide HÃ¤nde parallel
- âœ… 2x HandTracker (Kalman) + 2x GestureFSM
- âœ… OSC Pfade mit Hand-ID: `/hand/0/palm`, `/hand/1/palm`
- âœ… Debug-Overlay zeigt beide HÃ¤nde (unterschiedliche Farben)
- âœ… `TrackingResult.handId` fÃ¼r OSC-Routing
- âœ… Bounding Box um GANZE Hand (alle 21 Landmarks)

**Ergebnis:** 2 HÃ¤nde werden erkannt und gut getrackt! âœ…

### Phase 2.7: Gesten-Erkennung Fix - âœ… VEREINFACHT (Y-basiert)
**Problem:** WinkelabhÃ¤ngige Fehlerkennungen (FISTâ†”THUMBS_UP, POINTINGâ†”TWO/THREE, etc.)

**Ursache:**
- Komplexe Curl/Winkel-Berechnungen versagen bei verschiedenen Kamerawinkeln
- Keine Links/Rechts-Unterscheidung fÃ¼r Daumen

**Neuer Ansatz (nach Python/MediaPipe Artikel):**
- âœ… **Y-basierte Finger-Erkennung**: `tip.y < pip.y` = Finger oben
  - Simpel, robust, winkelunabhÃ¤ngig
  - Funktioniert weil Y immer "oben/unten" im Bild ist
- âœ… **X-basierte Daumen-Erkennung**: Unterscheidet Links/Rechts
  - Rechte Hand: `tip.x < ip.x` = Daumen ausgestreckt
  - Linke Hand: `tip.x > ip.x` = Daumen ausgestreckt
- âœ… **Automatische Handedness-Erkennung**:
  - Palm X < 0.5 = Rechte Hand (gespiegelte Ansicht)
  - Palm X > 0.5 = Linke Hand
- âœ… Alte Curl-Faktoren entfernt (zu komplex)
- âœ… Alte Winkelberechnungen entfernt (versagen bei Seitenansicht)

**Erwartete Verbesserungen:**
- FIST vs THUMBS_UP: Durch Links/Rechts-Unterscheidung
- POINTING vs TWO/THREE: Durch einfache Y-PrÃ¼fung
- FIVE vs FIST bei Winkel: Durch robuste Y-PrÃ¼fung

### Phase 2.8: False Positive Filter - âœ… FUNKTIONIERT
**Problem:** Gesicht wird als Hand erkannt (Nase/Mund-Bereich)

**LÃ¶sung: Haar Cascade Face Detector:**
- âœ… **OpenCV Haar Cascade** integriert (`haarcascade_frontalface_default.xml`)
- âœ… Face Detection auf NV12 Y-Channel (schnell, Grayscale)
- âœ… Gecached (alle 5 Frames neu detektiert)
- âœ… **Overlap-Check**: >30% Overlap mit Gesicht â†’ abgelehnt
- âœ… 20% Margin um Gesichtsbereich
- âœ… **Ergebnis: Null False Positives im Gesicht**

**Heuristische Filter (weiterhin aktiv):**
- âœ… Score-Threshold: 0.75
- âœ… Face-Zone: Obere 40%, Score < 0.85 â†’ reject
- âœ… Aspect-Ratio: 0.3 - 3.0
- âœ… Keypoint-Konsistenz


### Phase 2.1: TensorRT Engine Wrapper
- [x] TensorRTEngine.hpp/.cpp erstellen
- [x] Engine laden/erstellen (.onnx â†’ .engine)
- [x] Inference Methode (Input â†’ Output Buffer)
- [x] CUDA Memory Management

### Phase 2.2: Palm Detection
- [x] PalmDetector.hpp/.cpp erstellen
- [x] TFLite Model heruntergeladen (palm_detection_lite.tflite)
- [ ] TFLite â†’ ONNX konvertieren (auf Jetson: convert_to_onnx.py)
- [x] NV12 â†’ RGB Preprocessing (GPU)
- [x] Post-Processing (BBox, Score, Anchors)

### Phase 2.3: Hand Landmark
- [x] HandLandmark.hpp/.cpp erstellen
- [x] ROI Extraction aus Palm Detection
- [x] 21 Landmarks Output Parsing
- [x] Unletterbox Koordinaten

### Phase 2.4: ProcessingLoop Integration
- [x] PalmDetector + HandLandmark in ProcessingLoop einbinden
- [x] HandTracker + GestureFSM integrieren
- [x] TFLite Models heruntergeladen
- [ ] TFLite â†’ ONNX konvertieren (auf Jetson)
- [ ] Test: 30+ FPS mit NNs verifizieren

---

## ğŸ“… Roadmap

### âœ… Phase 1: Sensor-Only Pipeline - ERLEDIGT
**Ergebnis:** 30 FPS stabil auf Jetson

| Task | Status | Notes |
|------|--------|-------|
| PipelineManager: Mono L/R hinzufÃ¼gen | âœ… | THE_400_P @ 60fps |
| PipelineManager: RGB 640Ã—360 NV12 | âœ… | LETTERBOX mode |
| PipelineManager: Sync Node | âœ… | 10ms threshold |
| InputLoop: MessageGroup parsing | âœ… | rgb + monoLeft + monoRight |
| Types.hpp: V3 Konstanten | âœ… | GestureState, Point3D, etc. |
| Config: FPS auf 60 Ã¤ndern | âœ… | main.cpp |
| Test: 60 FPS verifizieren | â¬œ | Auf Jetson deployen |

### Phase 2: TensorRT Inference âœ…
**Ziel:** Hand-NNs auf Jetson mit TensorRT

| Task | Status | Notes |
|------|--------|-------|
| TensorRT Engine Wrapper | âœ… | Generische Klasse |
| Palm Detection TRT Engine | âœ… | .onnx â†’ .engine |
| Hand Landmark TRT Engine | âœ… | .onnx â†’ .engine |
| NV12 â†’ RGB Preprocessing (GPU) | âœ… | CUDA/NPP |
| LETTERBOX Preprocessing | âœ… | GPU-seitig |
| Unletterbox Postprocessing | âœ… | Koordinaten zurÃ¼ckmappen |
| ProcessingLoop Integration | âœ… | Inference Pipeline |
| Test: 30+ FPS verifizieren | âœ… | Mit beiden NNs |

### Phase 3: Stereo Depth (Punktuell)
**Ziel:** Z-Koordinate nur am Palm Center

| Task | Status | Notes |
|------|--------|-------|
| StereoDepth Klasse | âœ… | src/core/StereoDepth.cpp |
| OAK-D Kalibrierung laden | âœ… | Default-Werte implementiert |
| Lokales Stereo Matching (9Ã—9) | âœ… | SAD Block Matching |
| Median Filter fÃ¼r Robustheit | âœ… | robustMedian() |
| Z in Kamera-Koordinaten | âœ… | pixelTo3D() |
| Rectification Maps berechnen | â¬œ | TODO: OpenCV stereoRectify |
| Device Kalibrierung laden | â¬œ | dai::Device::readCalibration() |
| Test: Tiefe verifizieren | â¬œ | Bekannte AbstÃ¤nde |

### Phase 4: Kalman Tracking
**Ziel:** Glatte, prÃ¤diktive Trajektorien

| Task | Status | Notes |
|------|--------|-------|
| HandTracker Klasse | âœ… | src/core/HandTracker.cpp |
| 6-State Kalman Filter | âœ… | [x,y,z,vx,vy,vz] |
| VIP Lock Logic (15 Frames) | âœ… | ~250ms StabilitÃ¤t |
| Dropout Handling | âœ… | Pure Prediction |
| +1 Frame Prediction | âœ… | Latenz-Kompensation |
| One-Euro fÃ¼r Rotationen | â¬œ | Landmarks-relativ |
| Test: Jitter messen | â¬œ | <5ms Ïƒ Ziel |

### Phase 5: Gesture FSM
**Ziel:** Robuste Gesten-Erkennung

| Task | Status | Notes |
|------|--------|-------|
| GestureFSM Klasse | âœ… | src/core/GestureFSM.cpp |
| States definieren | âœ… | Idle/Palm/Pinch/Grab/Point |
| Hysteresis Thresholds | âœ… | Enter/Exit unterschiedlich |
| Debounce (3 Frames) | âœ… | ~50ms @ 60fps |
| Finger Extension Check | âœ… | Landmark-basiert |
| Test: Gesten-ÃœbergÃ¤nge | â¬œ | Kein Flackern |

### Phase 6: OSC Integration
**Ziel:** 30 Hz konstante Ausgabe

| Task | Status | Notes |
|------|--------|-------|
| 30 Hz Rate Limiting | â¬œ | Decoupled von FPS |
| Drop-Oldest >50ms | âœ… | Backpressure implementiert |
| /hand/palm Message | âœ… | x, y, z |
| /hand/velocity Message | âœ… | vx, vy, vz |
| /hand/gesture Message | âœ… | state, confidence, name |
| /hand/vip Message | âœ… | vipLocked |
| /service/status Message | â¬œ | Heartbeat |
| Test: E2E Latenz <60ms | â¬œ | Glass-to-OSC |

---

## ğŸ“‹ Quick Reference

### Wichtige Konstanten (V3)
```cpp
// Camera
CAMERA_FPS = 60
RGB_WIDTH = 640, RGB_HEIGHT = 360
MONO_WIDTH = 640, MONO_HEIGHT = 400

// Tracking
VIP_LOCK_FRAMES = 15
DROPOUT_LIMIT = 5

// Gestures
PINCH_THRESHOLD_ENTER = 0.08
PINCH_THRESHOLD_EXIT = 0.12
DEBOUNCE_FRAMES = 3

// OSC
OSC_RATE_HZ = 30
MAX_LATENCY_MS = 50
```

### Dateien die geÃ¤ndert werden
- `src/core/PipelineManager.cpp` - Sensor-Only Pipeline
- `include/core/PipelineManager.hpp` - Config Updates
- `src/core/InputLoop.cpp` - MessageGroup Parsing
- `src/main.cpp` - FPS Config
- `include/core/Types.hpp` - Neue Typen

### Neue Dateien (geplant)
- `src/inference/TensorRTEngine.cpp` - TRT Wrapper
- `src/inference/PalmDetector.cpp` - Palm Detection
- `src/inference/HandLandmark.cpp` - Landmark Inference
- `src/core/HandTracker.cpp` - Kalman Filter
- `src/core/GestureFSM.cpp` - Gesten State Machine
- `src/core/StereoDepth.cpp` - Punktuelle Tiefe

---

## ğŸ“ Notizen

### 2026-01-09
- V3 Architektur definiert: OAK-D = Sensor-Only
- Kernprinzip: "Wir bauen einen 3D-Controller, kein CV-System"
- XLink bleibt unidirektional (kein BBox-RÃ¼ckkanal-Problem)
- Start mit Phase 1: Sensor-Only Pipeline

**Umbau durchgefÃ¼hrt:**
- PipelineManager komplett auf Sensor-Only umgebaut
  - RGB 640Ã—360 NV12 @ 60fps (LETTERBOX)
  - Mono L/R 640Ã—400 GRAY8 @ 60fps
  - Sync Node mit 10ms Threshold
  - Keine NNs mehr auf OAK-D
- InputLoop nur noch Sync-Mode (kein Fallback auf RGB-only)
- Neue Komponenten implementiert:
  - HandTracker: Kalman Filter mit 6 States [x,y,z,vx,vy,vz]
  - GestureFSM: State Machine (Idle/Palm/Pinch/Grab/Point)
  - StereoDepth: Punktuelle Tiefe am Palm Center
- Types.hpp mit V3 Konstanten und neuen Typen

**NÃ¤chster Schritt:** Auf Jetson deployen und 60 FPS testen

---

## âš ï¸ Bekannte Risiken / Offene Punkte

1. **OAK-D PoE Reconnect:** 
   - Problem: Nach Neustart des Service verbindet sich OAK-D manchmal nicht (Reset Problem).
   - Workaround: Jetson neu starten. 
   - TODO: `scripts/fix_oak_reconnect.sh` testen und integrieren (SpÃ¤ter).

2. **PoE Bandwidth:** 60fps Ã— (RGB + 2Ã—Mono) = ~40-50 MB/s â†’ sollte passen (GigE = 125 MB/s)
3. **TensorRT Conversion:** Erster Start dauert lange (Engine Build).

---

## âœ… Erledigte Aufgaben

### ğŸ‰ MEILENSTEIN 2026-01-09: Erste funktionierende Hand-Erkennung
- [x] Palm Detection lÃ¤uft mit TensorRT
- [x] Hand Landmark extrahiert 21 Keypoints
- [x] Skeleton-Rendering im MJPEG-Preview
- [x] OSC sendet Tracking-Daten
- [x] HandTracker + GestureFSM integriert

### FrÃ¼here Aufgaben
- [x] OPTIMAL_WORKFLOW_V3.md erstellt
- [x] TODO.md erstellt
- [x] PipelineManager.cpp: V3 Sensor-Only Pipeline (RGB + Mono L/R + Sync)
- [x] PipelineManager.hpp: Config erweitert (monoWidth, monoHeight, enableStereo)
- [x] InputLoop.cpp: MessageGroup Parsing fÃ¼r Sync Queue
- [x] main.cpp: 30 FPS Config, enableStereo=false
- [x] Types.hpp: V3 Konstanten, GestureState enum, Point3D, Velocity3D
- [x] HandTracker.cpp/.hpp: 6-State Kalman Filter mit VIP Lock
- [x] GestureFSM.cpp/.hpp: Gesture State Machine mit Hysteresis
- [x] StereoDepth.cpp/.hpp: Punktuelle Tiefenmessung (9Ã—9 Window)
- [x] CMakeLists.txt: Neue Dateien hinzugefÃ¼gt
- [x] **CODE CLEANUP:**
  - [x] ProcessingLoop.cpp: Komplett neu geschrieben (815â†’250 Zeilen)
  - [x] ProcessingLoop.hpp: Vereinfacht, alte Filter entfernt
  - [x] Frame.hpp: nnData/palmData als DEPRECATED markiert
  - [x] docs/: Alte Dateien ins Archive verschoben
- [x] **OSC INTEGRATION (V3):**
  - [x] OscSender.cpp: /hand/palm (x,y,z) Message
  - [x] OscSender.cpp: /hand/velocity (vx,vy,vz) Message
  - [x] OscSender.cpp: /hand/gesture (state, confidence, name) Message
  - [x] OscSender.cpp: /hand/vip (locked) Message
- [x] **STATS & DEBUG:**
  - [x] ProcessingLoop: Hand-Stats im Terminal-Log
  - [x] ProcessingLoop: Hand-Info im MJPEG Debug-Overlay

